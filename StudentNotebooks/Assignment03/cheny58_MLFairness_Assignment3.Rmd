---
title: "MLFairness Assignment 3"
author: "Youjin Chen"
date: "09/24/2022"
output:
  html_document:
    toc: yes
  pdf_document:
    toc: yes
subtitle: ""
---

## Instructions (DELETE BEFORE SUBMISSION)

* Use this notebook is a template for your biweekly project status assignment. 
* Use the sections starting with **BiWeekly Work Summary** as your outline for your submitted notebook.
* Summarize ALL of your work in this notebook; **if you don't show and/or link to your work here, it doesn't exist for us!**

1. Create a new copy of this notebook in the `AssignmentX` sub-directory of your team's github repository using the following naming convention

   * `rcsid_assignmentX.Rmd` and `rcsid_assignmentX.pdf`
   * For example, `bennek_assignment03.Rmd`

2. Document **all** the work you did on your assigned project this week **using the outline below.** 

3. You MUST include figures and/or tables to illustrate your work. *Screen shots are okay*, but include something!

4. You MUST include links to other important resources (knitted HTMl files, Shiny apps). See the guide below for help.

5. Commit the source (`.Rmd`) and knitted (`.html`) versions of your notebook and push to github

6. **Submit a pull request.** Please notify Dr. Erickson if you don't see your notebook merged within one day. 

7. **DO NOT MERGE YOUR PULL REQUESTS YOURSELF!!**

See the Grading Rubric for guidance on how the contents of this notebook will be graded on lms. 

## Weekly Work Summary	

**NOTE:** Follow an outline format; use bullets to express individual points. 

* RCS ID: **cheny58** 
* Project Name: **Making use of aif360**
* Summary of work since last week 
  

* NEW: Summary of github issues added and worked 

    * Issues that you've submitted
    * Issues that you've self-assigned and addressed
    
* Summary of github commits 

    * include branch name(s)
    * include browsable links to all external files on github
    
* List of presentations,  papers, or other outputs

    * Include browsable links
    
* List of references (if necessary) 
* Indicate any use of group shared code base
* Indicate which parts of your described work were done by you or as part of joint efforts

## Personal Contribution	

* Clearly defined, unique contribution(s) done by you: code, ideas, writing...
* Include github issues you've addressed


## Discussion of Primary Findings 	

* Discuss primary findings: 

    * What did you want to know? 
    * How did you go about finding it? 
    * What did you find?
	
* **Required:** Provide illustrating figures and/or tables
     
    * Embed your code in this notebook if possible.
    * If not possible, screen shots are acceptable. 
    * If your figures are "live," either include source code embedded in notebook or provide github location for their source scripts.
    * If your contributions included things that are not done in an R-notebook, (e.g. researching, writing, and coding in Python), you still need to do this status notebook in R.  Describe what you did here and put any products that you created in github. If you are writing online documents (e.g. overleaf or google docs), you can include links to the documents in this notebook instead of actual text.
  ****
  
## Using AI Fairness 360 in R

  
### Load required libraries

We load the required libraries for this project.

```{r setup, include=FALSE}

# Set the default CRAN repository
local({r <- getOption("repos")
       r["CRAN"] <- "http://cran.r-project.org" 
       options(repos=r)
})

# Set code chunk defaults
knitr::opts_chunk$set(echo = TRUE)

# Load required packages; install if necessary
# CAUTION: DO NOT interrupt R as it installs packages!!

if (!require("ggplot2")) {
  install.packages("ggplot2")
  library(ggplot2)
}

if (!require("tidyverse")) {
  install.packages("tidyverse")
  library(tidyverse)
}

if (!require("mltools")) {
  install.packages("mltools")
  library(mltools)
}

if (!require("data.table")) {
  install.packages("data.table")
  library(data.table)
}

if (!require("fairness")) {
  install.packages("fairness")
  library(fairness)
}

if (!require("fairmodels")) {
  install.packages("fairmodels")
  library(fairmodels)
}

if (!require("mlr3measures")) {
  install.packages("mlr3measures")
  library(mlr3measures)
}

if (!require("caret")) {
  install.packages("caret")
  library(caret)
}

if (!require("aif360")) {
  install.packages("aif360")
  library(aif360)
}
```
### 2)Process and split data into train-test

We begin by splitting the data into train-test split.

```{r}
# Set seed for reproducibility
set.seed(0)
df = read_csv("processed_dataset.csv")
# Split data into train-test
# 70% data to be used for training 
# 30% data to be used for testing

# Get indices
training_size <- floor(0.7*nrow(df))
train_ind <- sample(seq_len(nrow(df)), size = training_size)

# Split data
names(df) <- make.names(names(df))
train.raw <- df[train_ind, ]
test.raw <- df[-train_ind, ]

# Scale train-test data
# except for income and gender
pp = preProcess(subset(train.raw, select = -c(`gender`, `income`)))
train.scale <- predict(pp, subset(train.raw, select = -c(`gender`, `income`)))
test.scale <- predict(pp, subset(test.raw, select = -c(`gender`, `income`)))

# Attach income and gender to scaled data
train.scale$income <- train.raw$income
test.scale$income <- test.raw$income
train.scale$gender <- train.raw$gender
test.scale$gender <- test.raw$gender
```


### 3) Data Preprocessing with AI Fairness 360
```{r}
# Apply reweighing before model training
# Get weights during Reweighing
reweighing_weights <- reweight(train.scale$gender, train.scale$income)
# Train a Logistic Regression model
reweighingModel <- glm(income ~ ., data = train.scale, family = binomial, weights = reweighing_weights)

# Get prediction on test data
reweighingModel.prob <- predict(reweighingModel, test.scale, type = 'response')
reweighingModel.pred <- ifelse(reweighingModel.prob > 0.5, 1, 0)

```
The following it copied and pasted from the github of the AIF360, since from the package of AIF360, there no function called "binary_label_dataset" which we need as a foundation of the following processing.
```{r}
list_of_list <- function(i){
  list(list(i))
}
list_fn <- function(i){
  list(i)
}

input_data <- function(inp){
  read.csv(inp)
}

binary_label_dataset <- function(data_path, favor_label,
                        unfavor_label, unprivileged_protected_attribute,
                        privileged_protected_attribute,
                        target_column, protected_attribute) {

  if (is.data.frame(data_path)) {
    dataframe <- r_to_py(data_path)
  } else if (file_test("-f", data_path) == TRUE) {
    dataframe = input_data(data_path)
  }
  unprivileged_protected_list <- list_of_list(unprivileged_protected_attribute)
  privileged_protected_list <- list_of_list(privileged_protected_attribute)
  target_column_list <- list_fn(target_column)
  protected_attribute_list <- list_fn(protected_attribute)

  return(datasets$BinaryLabelDataset(df = dataframe,
                                     favorable_label = favor_label,
                                     unfavorable_label = unfavor_label,
                                     unprivileged_protected_attributes = unprivileged_protected_list,
                                     privileged_protected_attributes = privileged_protected_list,
                                     label_names = target_column_list,
                                     protected_attribute_names = protected_attribute_list))

}

```

```{r}
bin_train <- binary_label_dataset(  data_path = train.scale, 
                                    favor_label = 1,
                                    unfavor_label = 0,
                                    target_column = 'income',
                                    unprivileged_protected_attribute = 1, 
                                    privileged_protected_attribute = 0,
                                    protected_attribute = "gender")

di <- aif360::disparate_impact_remover(repair_level = 1.0, sensitive_attribute='gender')
dataset_transf_train <- di$fit_transform(bin_train)
transformed <-as.data.frame(dataset_transf_train$convert_to_dataframe()[1])
```

```{r}
write.csv(transformed,"D:/RPI Fall2022/MATP4910/Transformed_data.csv", row.names = FALSE)

```



```{r}
#draft
# reweighing_weights <- aif360::reweighing(unprivileged_groups = list("gender",1),privileged_groups = list("gender",0))
# p <- list("gender", 1)
# u <- list("gender", 0)
# rw <- reweighing(u,p)
# bi_data <- train.scale[c("gender")]
# new_bm <- binary_label_dataset_metric(train.scale, list('gender', 1), list('gender',0))
```





